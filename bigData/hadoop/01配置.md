# 配置虚拟机
系统：centos7

注意：其他版本的linux系统操作、命令可能有所不同

## 软件安装
1、vim安装
``` sh
sudo yum seach vim
yum install -y vim_version
```
2、网络工具
``` sh
sudo yum search ifconfig
yum install -y net-tools.x86_64
``` 
3、软件包
`红帽系`OS系统额外提供的软件包，适用于RHEL、CentOS和Scientific相当于是一个软件仓库，大多数rpm包在官方repository中是找不到的
``` sh
yum install -y epel-release
```

## 虚拟机设置
1、克隆虚拟机(clone后，2、3、4、5步对各台虚拟机都要配置)
2、配置静态网络
`sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33`
3、虚拟机配置映射
``` sh
sudo vim /etc/hosts
#添加 192.168.xxx.xxx 主机名1
#添加 192.168.xxx.xxx 主机名2
#添加 192.168.xxx.xxx 主机名3
```
4、关闭防火墙
``` sh
systemctl stop firewalld
systemctl disable firewalld.service #使防火墙失效，systemctl enable firewalld.service(启动)
systemctl status firewalld #查看防火墙状态
```
5、卸载虚拟机自带JDK(**非必须**)
``` sh
1、rpm -qa | grep -i java | xargs -n1 rpm -e 
--nodeps
#rpm -qa：查询所安装的所有 rpm 软件包
#grep -i：忽略大小写
#xargs -n1：表示每次只传递一个参数
#rpm -e –nodeps：强制卸载软件
```
6、创建用户(**非必须**)
``` sh
useradd xxx #创建用户
passwd xxx #修改密码

#修改用户权限
sudo vim /etc/sudoers
#在wheel ALL=(ALL) ALL行下面添加
zhjl ALL=(ALL) NOPASSWD:ALL
```
7、windows配置映射
``` sh
1、目录：C:/windows/system32/drivers/etc/hosts
2、管理模式打开Power shell
3、notepad.exe 打开 hosts文件 
4、在末尾添加如下内容
#192.168.xxx.xxx 主机名1
#192.168.xxx.xxx 主机名2
#192.168.xxx.xxx 主机名3
``` 

## JDK、Hadoop安装
1、创建目录
``` sh
1、cd /opt
2、sudo mkdir module softwar
#修改目录所属人，否则会因为权限不足，产生传输错误
3、sudo chown zhjl:zhjl module software
```
2、传输软件
``` sh
cd /opt #将windows的JDK和Hadoop压缩包上传到虚拟机
``` 
3、解压JDK
``` sh
tar -zvxf jdk名字 -C /opt/module
```
4、配置JDK环境变量(方式不唯一)
``` sh
1、sudo vim /etc/profile.d/my_env.sh
#添加如下内容
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_341
export PATH=$PATH:$JAVA_HOME/bin

2、source /etc/profile #使环境变量.sh脚本文件生效

3、java -version #检查是否安装成功
```
5、解压Hadoop
``` sh
tar -zvxf hadoop名字 -C /opt/module
```
6、配置Hadoop环境变量(方式不唯一)
``` sh
1、sudo vim /etc/profile.d/my_env/sh
#添加以下内容
#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

2、source /etc/profile

3、hadoop version #检查是否安装成功
```

# 配置分发、同步脚本
## scp(secure copy 安全拷贝)
1、定义
`scp可以实现服务器与服务器之间的数据拷贝(from server1 to server2)`
2、语法
`scp -r $fdir/$fname $user@host:$fdir/$fname`
3、前提条件
`各个分发主机都已经创建好了/opt/moudle(即要进行分发的目录)，并且两个目录已经修改为了zhjl:zhjl
## rsync(远程同步工具)
1、定义
`rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点`

`rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去`


# 配置hadoop

## core-site.xml
``` sh
<configuration>
<!-- 指定 NameNode 的地址 -->
 <property>
 <name>fs.defaultFS</name>
 <value>hdfs://hadoop102:8020</value>
 </property>
 <!-- 指定 hadoop 数据的存储目录 -->
 <property>
 <name>hadoop.tmp.dir</name>
 <value>/opt/module/hadoop-3.3.3/data</value>
 </property>
 <!-- 配置 HDFS 网页登录使用的静态用户为 zhjl -->
 <property>
 <name>hadoop.http.staticuser.user</name>
 <value>zhjl</value>
 </property>
</configuration>
```

## hdfs
``` sh
<configuration>
<!-- nn web 端访问地址-->
<property>
 <name>dfs.namenode.http-address</name>
 <value>hadoop102:9870</value>
 </property>
<!-- 2nn web 端访问地址-->
 <property>
 <name>dfs.namenode.secondary.http-address</name>
 <value>hadoop104:9868</value>
 </property>
</configuration>
```

## yarn
``` sh
<configuration>
<!-- 指定 MR 走 shuffle -->
 <property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
 </property>
 <!-- 指定 ResourceManager 的地址-->
 <property>
 <name>yarn.resourcemanager.hostname</name>
 <value>hadoop103</value>
 </property>
 <!-- 环境变量的继承 -->
 <property>
 <name>yarn.nodemanager.env-whitelist</name>
 
<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO
NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP
RED_HOME</value>
 </property>
</configuration>
```

## mapred
``` sh
<configuration>
<property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
 </property>
</configuration>
```

## workers
``` sh
hadoop102
hadoop103
hadoop104
```

## 启动集群